\section{Test Cases}


\subsection{ \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T17}{ LVV-T17 }
             - AG-00-00: Installation of the Alert Generation science payload. }\label{lvv-t17}





\begin{longtable}[]{llllll}
\toprule
Version & Status & Priority & Verification Type & Critical Event & Owner
\\\midrule
1 & Approved & Normal & Test & False & Eric Bellm
\\\bottomrule
\end{longtable}

\subsubsection{Requirements}

\begin{itemize}

\item \href{https://jira.lsstcorp.org/browse/LVV-139}{ LVV-139 } - DMS-REQ-0308-V-01: Software Architecture to Enable Community Re-Use

\end{itemize}


\subsubsection{Test Items}

This test will check:

\begin{itemize}
\tightlist
\item
  That the Alert Generation science payload is available for
  distribution from documented channels;
\item
  That the Alert Generation science payload can be installed on LSST
  Data Facility-managed systems.
\end{itemize}





\subsubsection{Intercase Dependencies}

None.



\subsubsection{Environment Needs}

\paragraph{Software}

Software All prerequisite packages listed at
https://pipelines.lsst.io/install/ prereqs/centos.html must be available
on the test system and on the LSST-VC compute node.



\paragraph{Hardware}

Hardware This test case shall be executed on a developer system at NCSA
which serves as the ``head node'' or otherwise provides access to
filesystems shared by the LSST Verification Cluster (LSST-VC). We assume
that this system will be lsst-dev01.ncsa.illinois.edu and the filesystem
will be a GPFS-based system mounted at /software.\\
The test also requires access to one LSST-VC compute node.



\subsubsection{Input Specification}

No input data is required for this test case.



\subsubsection{Output Specification}

The Alert Generation science payload will be made available on a shared
filesystem accessible from LSST-VC compute notes.



\subsubsection{Test Procedure}

\begin{longtable}[]{p{1.3cm}p{2cm}p{13cm}}
%\toprule
Step & \multicolumn{2}{@{}l}{Description, Input Data and Expected Result} \\ \toprule
\endhead



\multirow{3}{*}{ 1 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Release 16.0 of the LSST Science Pipelines will be installed into the
GPFS filesystem accessible at /software on lsst-dev01 following the
instructions at \url{https://pipelines.lsst.io/install/newinstall.html}
.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize


\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 2 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
The lsst\_distrib top level package will be
enabled:\\[2\baselineskip]\hspace*{0.333em} ~ ~ ~source
/software/lsstsw/stack3/loadLSST.bash\\
\hspace*{0.333em} ~ ~ ~setup lsst\_distrib
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 3 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
The ``LSST Stack Demo'' package will be downloaded onto the test system
from
\href{https://github.com/lsst/lsst_dm_stack_demo/releases/tag/14.0}{https://github.com/lsst/lsst\_dm\_stack\_demo/releases/tag/16.0}
and uncompressed.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 4 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
The demo package will be executed by following the instructions in its
``README`` file. The string ``Ok.`` should be returned. Specifically, we
execute:\\
\hspace*{0.333em} ~ ~ ~setup obs\_sdss\\
\hspace*{0.333em} ~ ~ ~./bin/demo.sh\\
\hspace*{0.333em} ~ ~ ~python bin/compare
expected/Linux64/detected-sources.txt
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 5 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
A shell on an LSST-VC compute node will now be obtained by executing:\\
\hspace*{0.333em} ~ ~\$ srun -I --pty bash
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 6 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
The demo package will be executed on the compute node and the same
result obtained.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 7 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
The Alert Production datasets and packages are not yet part of
lsst\_distrib and so must be installed separately. They will be
installed as follows on the GPFS
filesystem:\\[2\baselineskip]\hspace*{0.333em} ~ setup git\_lfs\\
\hspace*{0.333em} ~ git clone
https://github.com/lsst/ap\_verify\_hits2015.git\\[2\baselineskip]\hspace*{0.333em}
~ export AP\_VERIFY\_HITS2015\_DIR=\$PWD/ap\_verify\_hits2015 cd
\$AP\_VERIFY\_HITS2015\_DIR\\
\hspace*{0.333em} ~ setup -r .\\
\hspace*{0.333em} ~ cd-\\
\hspace*{0.333em} ~\\
\hspace*{0.333em} ~ setup obs\_decam\\
\hspace*{0.333em} ~ git clone
https://github.com/lsst-dm/ap\_association\\
\hspace*{0.333em} ~ cd ap\_association\\
\hspace*{0.333em} ~ setup -k -r .\\
\hspace*{0.333em} ~ scons\\
\hspace*{0.333em} ~ cd-\\
\hspace*{0.333em} ~\\
\hspace*{0.333em} ~ git clone https://github.com/lsst-dm/ap\_pipe\\
\hspace*{0.333em} ~ cd ap\_pipe\\
\hspace*{0.333em} ~ setup -k -r .\\
\hspace*{0.333em} ~ scons\\
\hspace*{0.333em} ~ cd-\\
\hspace*{0.333em} ~\\
\hspace*{0.333em} ~ git clone https://github.com/lsst-dm/ap\_verify\\
\hspace*{0.333em} ~ cd ap\_verify\\
\hspace*{0.333em} ~ setup -k -r .\\
\hspace*{0.333em} ~ scons\\
\hspace*{0.333em} ~ cd-\\[2\baselineskip]and any errors or failures
reported.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule

\end{longtable}




\subsection{ \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T18}{ LVV-T18 }
             - AG-00-05: Alert Generation Produces Required Data Products }\label{lvv-t18}





\begin{longtable}[]{llllll}
\toprule
Version & Status & Priority & Verification Type & Critical Event & Owner
\\\midrule
1 & Approved & Normal & Test & False & Eric Bellm
\\\bottomrule
\end{longtable}

\subsubsection{Requirements}

\begin{itemize}

\item \href{https://jira.lsstcorp.org/browse/LVV-29}{ LVV-29 } - DMS-REQ-0069-V-01: Processed Visit Images

\item \href{https://jira.lsstcorp.org/browse/LVV-7}{ LVV-7 } - DMS-REQ-0010-V-01: Difference Exposures

\item \href{https://jira.lsstcorp.org/browse/LVV-100}{ LVV-100 } - DMS-REQ-0269-V-01: DIASource Catalog

\item \href{https://jira.lsstcorp.org/browse/LVV-102}{ LVV-102 } - DMS-REQ-0271-V-01: DIAObject Catalog

\end{itemize}


\subsubsection{Test Items}

This test will check that the basic data products produced by Alert
Generation are generated by execution of the science payload.\\
These products will include:

\begin{itemize}
\tightlist
\item
  Processed visit images (PVIs; DMS-REQ-0069); â€¢ Difference Exposures
  (DMS-REQ-0010);
\item
  DIASource catalogs (DMS-REQ-0269);
\item
  DIAObject catalogs (DMS-REQ-0271);
\end{itemize}





\subsubsection{Intercase Dependencies}

LVV-T-17 (AG-00-00)



\subsubsection{Environment Needs}

\paragraph{Software}

Release 16.0 of the DM Software Stack will be pre-installed (following
the procedure described in AG-00-00).



\paragraph{Hardware}

The test shall be carried out on a machine with at least 16 GB of RAM
and multiple CPU cores which has access to the /datasets shared (GPFS)
filesystem at the LSST Data Facility.



\subsubsection{Input Specification}

A complete processing of the DECam ``HiTS'' dataset, as defined at
https://dmtn-039.lsst.io/ and
https://github.com/lsst/ap\_verify\_hits2015, through the Alert
Generation science payload.\\
This dataset shall be made available in a standard LSST data repository,
accessible via the ``Data Butler''.\\
It is not required that all combinations of visit and CCD have been
processed successfully: a number of failures are expected. However,
documentation to describe processing failures should be provided.



\subsubsection{Output Specification}

None.



\subsubsection{Test Procedure}

\begin{longtable}[]{p{1.3cm}p{2cm}p{13cm}}
%\toprule
Step & \multicolumn{2}{@{}l}{Description, Input Data and Expected Result} \\ \toprule
\endhead



\multirow{3}{*}{ 1 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
The DM Stack and Alert Processing packaged shall be initialized as
described in LVT-T17 (AG-00-00).
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize


\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 2 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
The alert generation processing will be executed using the verification
cluster:\\[2\baselineskip]```bash\\
python ap\_verify/bin/prepare\_demo\_slurm\_files.py\\
\# At present we must run a single ccd+visit to handle ingestion
before\\
\# parallel processing can begin\\
./ap\_verify/bin/exec\_demo\_run\_1ccd.sh 410915 25\\
ln -s ap\_verify/bin/demo\_run.sl\\
ln -s ap\_verify/bin/demo\_cmds.conf\\
sbatch demo\_run.sl\\
```\\[2\baselineskip]and any errors or failures reported.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 3 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
A ``Data Butler'' will be initialized to access the repository.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 4 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
For each of the expected data products types (listed in Â§4.2.2) and each
of the expected units (PVIs, catalogs, etc.), the data product will be
retrieved from the Butler and verified to be non-empty.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 5 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
DIAObjects are currently only stored in a database, without shims to the
Butler, so the existence of the database table and its non-empty
contents will be verified by directly accessing it using sqlite3 and
executing appropriate SQL queries.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule

\end{longtable}




\subsection{ \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T19}{ LVV-T19 }
             - AG-00-10: Scientific Verification of Processed Visit Images }\label{lvv-t19}





\begin{longtable}[]{llllll}
\toprule
Version & Status & Priority & Verification Type & Critical Event & Owner
\\\midrule
1 & Approved & Normal & Test & False & Eric Bellm
\\\bottomrule
\end{longtable}

\subsubsection{Requirements}

\begin{itemize}

\item \href{https://jira.lsstcorp.org/browse/LVV-29}{ LVV-29 } - DMS-REQ-0069-V-01: Processed Visit Images

\item \href{https://jira.lsstcorp.org/browse/LVV-158}{ LVV-158 } - DMS-REQ-0327-V-01: Background Model Calculation

\item \href{https://jira.lsstcorp.org/browse/LVV-12}{ LVV-12 } - DMS-REQ-0029-V-01: Generate Photometric Zeropoint for Visit Image

\item \href{https://jira.lsstcorp.org/browse/LVV-30}{ LVV-30 } - DMS-REQ-0070-V-01: Generate PSF for Visit Images

\item \href{https://jira.lsstcorp.org/browse/LVV-13}{ LVV-13 } - DMS-REQ-0030-V-01: Generate WCS for Visit Images

\item \href{https://jira.lsstcorp.org/browse/LVV-31}{ LVV-31 } - DMS-REQ-0072-V-01: Processed Visit Image Content

\end{itemize}


\subsubsection{Test Items}

This test will check that the Processed Visit Images (PVIs) delivered by
the alert generation science payload meet the requirements laid down by
LSE-61.\\
Specifically, this will demonstrate that:

\begin{itemize}
\tightlist
\item
  Processed visit images have been generated and persisted during
  payload execution;
\item
  Each PVI includes a science pixel array, a mask array, and a variance
  array. (DMS-REQ-0072).
\item
  Each PVI includes a background model (DMS-REQ-0327), photometric
  zero-point (DMS- REQ-0029), spatially-varying PSF (DMS-REQ-0070) and
  WCS (DMS-REQ-0030).
\item
  Saturated pixels are correctly masked.
\item
  Pixels affected by cosmic rays are correctly masked.
\item
  The background is not oversubtracted around bright objects.
\end{itemize}

This test does not include quantitative targets for the science quality
criteria.





\subsubsection{Intercase Dependencies}

LVT-T17 (AG-00-00)\\
LVT-T18 (AG-00-05)



\subsubsection{Environment Needs}

\paragraph{Software}

Release 14.0 of the DM Software Stack will be pre-installed (following
the procedure described in AG-00-00).



\paragraph{Hardware}

The test shall be carried out on a machine with at least 16 GB of RAM
and multiple CPU cores which has access to the /datasets shared (GPFS)
filesystem at the LSST Data Facility.



\subsubsection{Input Specification}

A complete processing of the DECam ``HiTS'' dataset, as defined at
https://dmtn-039.lsst.io/ and
https://github.com/lsst/ap\_verify\_hits2015, through the Alert
Generation science payload.\\
This dataset shall be made available in a standard LSST data repository,
accessible via the ``Data Butler''.\\
It is not required that all combinations of visit and CCD have been
processed successfully: a number of failures are expected. However,
documentation to describe processing failures should be provided.



\subsubsection{Output Specification}

None.



\subsubsection{Test Procedure}

\begin{longtable}[]{p{1.3cm}p{2cm}p{13cm}}
%\toprule
Step & \multicolumn{2}{@{}l}{Description, Input Data and Expected Result} \\ \toprule
\endhead



\multirow{3}{*}{ 1 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
The DM Stack shall be initialized using the loadLSST script (as
described in LVV-T17 - AG-00-00).
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize


\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 2 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
A ``Data Butler'' will be initialized to access the repository.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 3 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
For each processed CCD, the PVI will be retrieved from the Butler, and
the existence of all components described in Â§4.3.2 will be verified.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 4 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Five sensors will be chosen at random from each of two visits and
inspected by eye for unmasked artifacts.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule

\end{longtable}




\subsection{ \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T20}{ LVV-T20 }
             - AG-00-15: Scientific Verification of Difference Images }\label{lvv-t20}





\begin{longtable}[]{llllll}
\toprule
Version & Status & Priority & Verification Type & Critical Event & Owner
\\\midrule
1 & Approved & Normal & Test & False & Eric Bellm
\\\bottomrule
\end{longtable}

\subsubsection{Requirements}

\begin{itemize}

\item \href{https://jira.lsstcorp.org/browse/LVV-7}{ LVV-7 } - DMS-REQ-0010-V-01: Difference Exposures

\item \href{https://jira.lsstcorp.org/browse/LVV-32}{ LVV-32 } - DMS-REQ-0074-V-01: Difference Exposure Attributes

\end{itemize}


\subsubsection{Test Items}

This test will check that the difference images delivered by the Alert
Generation science pay- load meet the requirements laid down by
LSE-61.\\
Specifically, this will demonstrate that:

\begin{itemize}
\tightlist
\item
  Difference images have been generated and persisted during payload
  execution;
\item
  Each difference image includes information about the identity of the
  input exposures, and metadata such as a representation of the PSF
  matching kernel (DMS-REQ-0074);
\item
  Masks are correctly propagated from the input images.
\end{itemize}

This test does not include quantitative targets for the science quality
criteria.





\subsubsection{Intercase Dependencies}

LVV-T17 (AG-00-00)\\
LVV-T18 (AG-00-05)



\subsubsection{Environment Needs}

\paragraph{Software}

Release 14.0 of the DM Software Stack will be pre-installed (following
the procedure described in AG-00-00).



\paragraph{Hardware}

The test shall be carried out on a machine with at least 16 GB of RAM
and multiple CPU cores which has access to the /datasets shared (GPFS)
filesystem at the LSST Data Facility.



\subsubsection{Input Specification}

A complete processing of the DECam ``HiTS'' dataset, as defined at
https://dmtn-039.lsst. io/ and
https://github.com/lsst/ap\_verify\_hits2015, through the Alert
Generation science payload.\\
This dataset shall be made available in a standard LSST data repository,
accessible via the ``Data Butler''.\\
It is not required that all combinations of visit and CCD have been
processed successfully: a number of failures are expected. However,
documentation to describe processing failures should be provided.



\subsubsection{Output Specification}

None.



\subsubsection{Test Procedure}

\begin{longtable}[]{p{1.3cm}p{2cm}p{13cm}}
%\toprule
Step & \multicolumn{2}{@{}l}{Description, Input Data and Expected Result} \\ \toprule
\endhead



\multirow{3}{*}{ 1 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
The DM Stack shall be initialized using the loadLSST script (as
described in LVV-T-17 AG-00-00).
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize


\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 2 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
A ``Data Butler'' will be initialized to access the repository.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 3 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
For each processed CCD, the difference image will be retrieved from the
Butler, and the existence of all components described in Â§4.4.2 will be
verified.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 4 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Five sensors will be chosen at random from each of two visits and the
masks of the input and difference images compared by eye.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule

\end{longtable}




\subsection{ \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T21}{ LVV-T21 }
             - AG-00-20: Scientific Verification of DIASource Catalog }\label{lvv-t21}





\begin{longtable}[]{llllll}
\toprule
Version & Status & Priority & Verification Type & Critical Event & Owner
\\\midrule
1 & Approved & Normal & Test & False & Eric Bellm
\\\bottomrule
\end{longtable}

\subsubsection{Requirements}

\begin{itemize}

\item \href{https://jira.lsstcorp.org/browse/LVV-100}{ LVV-100 } - DMS-REQ-0269-V-01: DIASource Catalog

\item \href{https://jira.lsstcorp.org/browse/LVV-101}{ LVV-101 } - DMS-REQ-0270-V-01: Faint DIASource Measurements

\item \href{https://jira.lsstcorp.org/browse/LVV-178}{ LVV-178 } - DMS-REQ-0347-V-01: Measurements in catalogs

\item \href{https://jira.lsstcorp.org/browse/LVV-162}{ LVV-162 } - DMS-REQ-0331-V-01: Computing Derived Quantities

\end{itemize}


\subsubsection{Test Items}

This test will check that the difference image source catalogs delivered
by the Alert Generation science payload meet the requirements laid down
by LSE-61.

\begin{itemize}
\tightlist
\item
  Specifically, this will demonstrate that:
\item
  Measurements in the catalog are presented in flux units
  (DMS-REQ-0347);
\item
  Each DIASource record contains an appropriate subset of the attributes
  required by DMS-REQ-0269. In particular, the LDM-503-3-era pipeline is
  expected to provide DIASource positions (sky and focal plane), fluxes,
  and flags indicative of issues encountered during processing.
\item
  Faint DIASources satisfying additional criteria are stored
  (DMS-REQ-0270).
\item
  Derived quantities are provided in pre-computed columns
  (DMS-REQ-0331);
\end{itemize}

This test does not include quantitative targets for the science quality
criteria.\\[2\baselineskip]





\subsubsection{Intercase Dependencies}

LVT-T17 (AG-00-00)\\
LVT-T18 (AG-00-05)



\subsubsection{Environment Needs}

\paragraph{Software}

Release 14.0 of the DM Software Stack will be pre-installed (following
the procedure described in AG-00-00).



\paragraph{Hardware}

The test shall be carried out on a machine with at least 16 GB of RAM
and multiple CPU cores which has access to the /datasets shared (GPFS)
filesystem at the LSST Data Facility.



\subsubsection{Input Specification}

A complete processing of the DECam ``HiTS'' dataset, as defined at
https://dmtn-039.lsst. io/ and
https://github.com/lsst/ap\_verify\_hits2015, through the Alert
Generation science payload.\\
This dataset shall be made available in a standard LSST data repository,
accessible via the ``Data Butler''.\\
It is not required that all combinations of visit and CCD have been
processed successfully: a number of failures are expected. However,
documentation to describe processing failures should be provided.



\subsubsection{Output Specification}

None.



\subsubsection{Test Procedure}

\begin{longtable}[]{p{1.3cm}p{2cm}p{13cm}}
%\toprule
Step & \multicolumn{2}{@{}l}{Description, Input Data and Expected Result} \\ \toprule
\endhead



\multirow{3}{*}{ 1 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
The DM Stack shall be initialized using the loadLSST script (as
described in LVV-T17 - AG-00-00).
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize


\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 2 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
A ``Data Butler'' will be initialized to access the repository.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 3 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
DIASource records will be accessed by querying the Butler, then examined
interactively at a Python prompt.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule

\end{longtable}




\subsection{ \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T22}{ LVV-T22 }
             - AG-00-25: Scientific Verification of DIAObject Catalog }\label{lvv-t22}





\begin{longtable}[]{llllll}
\toprule
Version & Status & Priority & Verification Type & Critical Event & Owner
\\\midrule
1 & Approved & Normal & Test & False & Eric Bellm
\\\bottomrule
\end{longtable}

\subsubsection{Requirements}

\begin{itemize}

\item \href{https://jira.lsstcorp.org/browse/LVV-116}{ LVV-116 } - DMS-REQ-0285-V-01: Level 1 Source Association

\item \href{https://jira.lsstcorp.org/browse/LVV-102}{ LVV-102 } - DMS-REQ-0271-V-01: DIAObject Catalog

\item \href{https://jira.lsstcorp.org/browse/LVV-103}{ LVV-103 } - DMS-REQ-0272-V-01: DIAObject Attributes

\item \href{https://jira.lsstcorp.org/browse/LVV-178}{ LVV-178 } - DMS-REQ-0347-V-01: Measurements in catalogs

\item \href{https://jira.lsstcorp.org/browse/LVV-162}{ LVV-162 } - DMS-REQ-0331-V-01: Computing Derived Quantities

\end{itemize}


\subsubsection{Test Items}

This test will check that the DIAObject catalogs delivered by the Alert
Generation science pay- load meet the requirements laid down by
LSE-61.\\
Specifically, this will demonstrate that:

\begin{itemize}
\tightlist
\item
  DIAObjects are recorded with unique identifiers (DMS-REQ-0271);
\item
  Measurements in the catalog are presented in flux units
  (DMS-REQ-0347);
\item
  EachDIAObjectrecordcontainscontainsanappropriatesetofsummaryattributes(DMS-
  REQ-0271 and DMS-REQ-0272). Note:

  \begin{itemize}
  \tightlist
  \item
    This test is executed independently of the Data Release Production
    system. Hence, DIAObjects are not associated to Objects, and the
    association metadata specified by DMS-REQ-0271 is not expected to be
    available.
  \item
    TheLDM-503-3erapipelineisnotexpectedtocalculateorpersistallattributesspec-
    ified by DMS-REQ-0272 requirement.
  \end{itemize}
\item
  Relevant derived quantities are provided in pre-computed columns
  (DMS-REQ-0331);~
\end{itemize}

This test does not include quantitative targets for the science quality
criteria.





\subsubsection{Intercase Dependencies}

LVT-T17 (AG-00-00)\\
LVT-T18 (AG-00-05)



\subsubsection{Environment Needs}

\paragraph{Software}

Release 14.0 of the DM Software Stack will be pre-installed (following
the procedure described in AG-00-00).



\paragraph{Hardware}

The test shall be carried out on a machine with at least 16 GB of RAM
and multiple CPU cores which has access to the /datasets shared (GPFS)
filesystem at the LSST Data Facility.



\subsubsection{Input Specification}

A complete processing of the DECam ``HiTS'' dataset, as defined at
https://dmtn-039.lsst. io/ and
https://github.com/lsst/ap\_verify\_hits2015, through the Alert
Generation science payload.\\
This dataset shall be made available in a standard LSST data repository,
accessible via the ``Data Butler''.\\
It is not required that all combinations of visit and CCD have been
processed successfully: a number of failures are expected. However,
documentation to describe processing failures should be provided.



\subsubsection{Output Specification}

None.



\subsubsection{Test Procedure}

\begin{longtable}[]{p{1.3cm}p{2cm}p{13cm}}
%\toprule
Step & \multicolumn{2}{@{}l}{Description, Input Data and Expected Result} \\ \toprule
\endhead



\multirow{3}{*}{ 1 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
The DM Stack shall be initialized using the loadLSST script (as
described in LVV-T17 - AG-00-00).
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize


\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 2 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
sqlite3 or Python's sqlalchemy module will be used to access the Level 1
database.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
-
\vspace{\dp0}
} \end{minipage} 


\\ \midrule

\end{longtable}




\subsection{ \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T216}{ LVV-T216 }
             - Installation of the Alert Distribution payloads. }\label{lvv-t216}





\begin{longtable}[]{llllll}
\toprule
Version & Status & Priority & Verification Type & Critical Event & Owner
\\\midrule
1 & Draft & Normal & Test & False & Eric Bellm
\\\bottomrule
\end{longtable}

\subsubsection{Requirements}

\begin{itemize}

\item \href{https://jira.lsstcorp.org/browse/LVV-139}{ LVV-139 } - DMS-REQ-0308-V-01: Software Architecture to Enable Community Re-Use

\end{itemize}


\subsubsection{Test Items}

This test will check:\\[2\baselineskip]

\begin{itemize}
\tightlist
\item
  That the Alert Distribution payloads are available from documented
  channels.
\item
  That the Alert Distribution payloads can be installed on LSST Data
  Facility-managed systems.
\item
  That the Alert Distribution payloads can be executed by LSST Data
  Facility-managed systems.
\end{itemize}





\subsubsection{Intercase Dependencies}


\subsubsection{Environment Needs}

\paragraph{Software}


\paragraph{Hardware}

This test case shall be executed on the Kubernetes Commons at the LDF.\\
As discussed in https://dmtn-028.lsst.io/ and https://dmtn-081.lsst.io/,
the test machine should have at least 16 cores, 64 GB of memory and
access to at least 1.5 TB of shared storage.



\subsubsection{Input Specification}


\subsubsection{Output Specification}


\subsubsection{Test Procedure}

\begin{longtable}[]{p{1.3cm}p{2cm}p{13cm}}
%\toprule
Step & \multicolumn{2}{@{}l}{Description, Input Data and Expected Result} \\ \toprule
\endhead



\multirow{3}{*}{ 1 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Download Kafka Docker image from
https://github.com/lsst-dm/alert\_stream.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
Runs without error

\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 2 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Change to the alert\_stream directory and build the docker image.\\

\begin{verbatim}
docker build -t "lsst-kub001:5000/alert_stream"
\end{verbatim}
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
Runs without error

\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 3 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Register it with Kubernetes\\[2\baselineskip]docker push
lsst-kub001:5000/alert\_stream
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
Runs without error

\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 4 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
From the alert\_stream/kubernetes directory, start Kafka and
Zookeeper:\\[2\baselineskip]

\begin{verbatim}
kubectl create -f zookeeper-service.yaml
kubectl create -f zookeeper-deployment.yaml
kubectl create -f kafka-deployment.yaml
kubectl create -f kafka-service.yaml
\end{verbatim}

(use kubectl get pods/services between each command to check status;
wait until each is ``Running'' before starting the next
command)\\[2\baselineskip]
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
Runs without error

\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 5 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Confirm Kafka and Zookeeper are listed when
running\\[2\baselineskip]kubectl get
pods\\[2\baselineskip]and\\[2\baselineskip]kubectl get services
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
Output should be similar to:\\[2\baselineskip]kubectl get pods\\
NAME ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~READY ~ ~ STATUS ~ ~RESTARTS ~ AGE\\
kafka-768ddf5564-xwgvh ~ ~ ~1/1 ~ ~ ~ Running ~ 0 ~ ~ ~ ~ ~31s\\
zookeeper-f798cc548-mgkpn ~ 1/1 ~ ~ ~ Running ~ 0 ~ ~ ~ ~
~1m\\[2\baselineskip]kubectl get services\\
NAME ~ ~ ~ ~TYPE ~ ~ ~ ~CLUSTER-IP ~ ~ ~EXTERNAL-IP ~ PORT(S) ~ ~ AGE\\
kafka ~ ~ ~ ClusterIP ~ 10.105.19.124 ~ \textless{}none\textgreater{} ~
~ ~ ~9092/TCP ~ ~6s\\
zookeeper ~ ClusterIP ~ 10.97.110.124 ~ \textless{}none\textgreater{} ~
~ ~ ~32181/TCP ~ 2m

\vspace{\dp0}
} \end{minipage} 


\\ \midrule

\end{longtable}




\subsection{ \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T217}{ LVV-T217 }
             - Full Stream Alert Distribution }\label{lvv-t217}





\begin{longtable}[]{llllll}
\toprule
Version & Status & Priority & Verification Type & Critical Event & Owner
\\\midrule
1 & Draft & Normal & Test & False & Eric Bellm
\\\bottomrule
\end{longtable}

\subsubsection{Requirements}

\begin{itemize}

\item \href{https://jira.lsstcorp.org/browse/LVV-3}{ LVV-3 } - DMS-REQ-0002-V-01: Transient Alert Distribution

\end{itemize}


\subsubsection{Test Items}

This test will check that the full stream of LSST alerts can be
distributed to end users.\\[2\baselineskip]Specifically, this will
demonstrate that:

\begin{itemize}
\tightlist
\item
  Serialized alert packets can be loaded into the alert distribution
  system at LSST-relevant scales (10,000 alerts every 39 seconds);
\item
  Alert packets can be retrieved from the queue system at LSST-relevant
  scales.
\end{itemize}





\subsubsection{Intercase Dependencies}

\href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T216}{LVV-T216}



\subsubsection{Environment Needs}

\paragraph{Software}

The Kafka cluster and Zookeeper shall be instantiated according to the
procedure described in
\href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T216}{LVV-T216}.



\paragraph{Hardware}

This test case shall be executed on the Kubernetes Commons at the LDF.\\
As discussed in https://dmtn-028.lsst.io/ and https://dmtn-081.lsst.io/,
the test machine should have at least 16 cores, 64 GB of memory and
access to at least 1.5 TB of shared storage.



\subsubsection{Input Specification}

Input data: A sample of Avro-formatted alert packets.



\subsubsection{Output Specification}

Multiple Kafka consumers will run and write log files to disk.\\
The logs will include printing every \emph{Nth} alert to to the log as
well as a log summarizing the queue offset.



\subsubsection{Test Procedure}

\begin{longtable}[]{p{1.3cm}p{2cm}p{13cm}}
%\toprule
Step & \multicolumn{2}{@{}l}{Description, Input Data and Expected Result} \\ \toprule
\endhead






\multirow{3}{*}{\parbox{1.3cm}{ 1-1 {\scriptsize from \hyperref[lvv-t216]{LVV-T216} } } } 
& {\small Description} &
\begin{minipage}[t]{13cm}{\scriptsize
Download Kafka Docker image from
https://github.com/lsst-dm/alert\_stream.

\vspace{\dp0}
} \end{minipage} \\ \cdashline{2-3}
& {\small Test Data} & 
\begin{minipage}[t]{13cm}{\scriptsize

No data.
\vspace{\dp0}

} \end{minipage} \\ \cdashline{2-3}
& {\small Expected Result} &

\begin{minipage}[t]{13cm}{\scriptsize
Runs without error

\vspace{\dp0}
} \end{minipage}

\\ \hdashline



\multirow{3}{*}{\parbox{1.3cm}{ 1-2 {\scriptsize from \hyperref[lvv-t216]{LVV-T216} } } } 
& {\small Description} &
\begin{minipage}[t]{13cm}{\scriptsize
Change to the alert\_stream directory and build the docker image.\\

\begin{verbatim}
docker build -t "lsst-kub001:5000/alert_stream"
\end{verbatim}

\vspace{\dp0}
} \end{minipage} \\ \cdashline{2-3}
& {\small Test Data} & 
\begin{minipage}[t]{13cm}{\scriptsize

No data.
\vspace{\dp0}

} \end{minipage} \\ \cdashline{2-3}
& {\small Expected Result} &

\begin{minipage}[t]{13cm}{\scriptsize
Runs without error

\vspace{\dp0}
} \end{minipage}

\\ \hdashline



\multirow{3}{*}{\parbox{1.3cm}{ 1-3 {\scriptsize from \hyperref[lvv-t216]{LVV-T216} } } } 
& {\small Description} &
\begin{minipage}[t]{13cm}{\scriptsize
Register it with Kubernetes\\[2\baselineskip]docker push
lsst-kub001:5000/alert\_stream

\vspace{\dp0}
} \end{minipage} \\ \cdashline{2-3}
& {\small Test Data} & 
\begin{minipage}[t]{13cm}{\scriptsize

No data.
\vspace{\dp0}

} \end{minipage} \\ \cdashline{2-3}
& {\small Expected Result} &

\begin{minipage}[t]{13cm}{\scriptsize
Runs without error

\vspace{\dp0}
} \end{minipage}

\\ \hdashline



\multirow{3}{*}{\parbox{1.3cm}{ 1-4 {\scriptsize from \hyperref[lvv-t216]{LVV-T216} } } } 
& {\small Description} &
\begin{minipage}[t]{13cm}{\scriptsize
From the alert\_stream/kubernetes directory, start Kafka and
Zookeeper:\\[2\baselineskip]

\begin{verbatim}
kubectl create -f zookeeper-service.yaml
kubectl create -f zookeeper-deployment.yaml
kubectl create -f kafka-deployment.yaml
kubectl create -f kafka-service.yaml
\end{verbatim}

(use kubectl get pods/services between each command to check status;
wait until each is ``Running'' before starting the next
command)\\[2\baselineskip]

\vspace{\dp0}
} \end{minipage} \\ \cdashline{2-3}
& {\small Test Data} & 
\begin{minipage}[t]{13cm}{\scriptsize

No data.
\vspace{\dp0}

} \end{minipage} \\ \cdashline{2-3}
& {\small Expected Result} &

\begin{minipage}[t]{13cm}{\scriptsize
Runs without error

\vspace{\dp0}
} \end{minipage}

\\ \hdashline



\multirow{3}{*}{\parbox{1.3cm}{ 1-5 {\scriptsize from \hyperref[lvv-t216]{LVV-T216} } } } 
& {\small Description} &
\begin{minipage}[t]{13cm}{\scriptsize
Confirm Kafka and Zookeeper are listed when
running\\[2\baselineskip]kubectl get
pods\\[2\baselineskip]and\\[2\baselineskip]kubectl get services

\vspace{\dp0}
} \end{minipage} \\ \cdashline{2-3}
& {\small Test Data} & 
\begin{minipage}[t]{13cm}{\scriptsize

No data.
\vspace{\dp0}

} \end{minipage} \\ \cdashline{2-3}
& {\small Expected Result} &

\begin{minipage}[t]{13cm}{\scriptsize
Output should be similar to:\\[2\baselineskip]kubectl get pods\\
NAME ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~READY ~ ~ STATUS ~ ~RESTARTS ~ AGE\\
kafka-768ddf5564-xwgvh ~ ~ ~1/1 ~ ~ ~ Running ~ 0 ~ ~ ~ ~ ~31s\\
zookeeper-f798cc548-mgkpn ~ 1/1 ~ ~ ~ Running ~ 0 ~ ~ ~ ~
~1m\\[2\baselineskip]kubectl get services\\
NAME ~ ~ ~ ~TYPE ~ ~ ~ ~CLUSTER-IP ~ ~ ~EXTERNAL-IP ~ PORT(S) ~ ~ AGE\\
kafka ~ ~ ~ ClusterIP ~ 10.105.19.124 ~ \textless{}none\textgreater{} ~
~ ~ ~9092/TCP ~ ~6s\\
zookeeper ~ ClusterIP ~ 10.97.110.124 ~ \textless{}none\textgreater{} ~
~ ~ ~32181/TCP ~ 2m

\vspace{\dp0}
} \end{minipage}

\\ \hdashline




\\ \midrule



\multirow{3}{*}{ 2 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Start a consumer that monitors the full stream and logs a deserialized
version of every Nth packet:\\

\begin{verbatim}
kubectl create -f consumerall-deployment.yaml
\end{verbatim}
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
Runs without error

\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 3 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
\begin{verbatim}
Start a producer that reads alert packets from disk and loads them into the Kafka queue:
\end{verbatim}

\begin{verbatim}
kubectl create -f sender-deployment.yaml
\end{verbatim}
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
Runs without error

\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 4 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Determine the name of the alert sender pod with\\[2\baselineskip]kubectl
get pods\\[2\baselineskip]Examine output log
files.\\[2\baselineskip]kubectl logs \textless{}pod
name\textgreater{}\\[2\baselineskip]Verify that alerts are being sent
within 40 seconds by subtracting the timing measurements.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
Similar to\\[2\baselineskip]kubectl logs sender-7d6f98586f-nhwfj\\
visit: 1570. ~ ~ time: 1530588618.0313473\\
visits finished: 1 ~ ~ ~time: 1530588653.5614944\\
visit: 1571. ~ ~ time: 1530588657.0087624\\
visits finished: 2 ~ ~ ~time: 1530588692.506188\\
visit: 1572. ~ ~ time: 1530588696.0051727\\
visits finished: 3 ~ ~ ~time: 1530588731.5900314\\[3\baselineskip]

\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 5 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Determine the name of the consumer pod with\\[2\baselineskip]kubectl get
pods\\[2\baselineskip]Examine output log files.\\[2\baselineskip]kubectl
logs \textless{}pod name\textgreater{}\\[2\baselineskip]The packet log
should show deserialized alert packets with contents matching the input
packets.\\[2\baselineskip]
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
Similar to \{'alertId': 12132024420, `l1dbId': 71776805594116,
`diaSource': \{'diaSourceId':\\
73499448928374785, `ccdVisitId': 2020011570, `diaObjectId':
71776805594116, 'ssO\\
bjectId': None, `parentDiaSourceId': None, `midPointTai': 59595.37041,
'filterNa\\
me': `y', `ra': 172.24912810036074, `decl': -80.64214929176521,
`ra\_decl\_Cov': \{\\
`raSigma': 0.0003428002819418907, `declSigma': 0.00027273103478364646,
'ra\_decl\_\\
Cov': 0.000628734880592674\}, `x': 2979.08837890625, `y':
3843.328857421875, 'x\_y\\
\_Cov': \{'xSigma': 0.6135467886924744, `ySigma': 0.77132648229599,
`x\_y\_Cov': 0.0\\
007463791407644749\}, `apFlux': None, `apFluxErr': None, `snr':
0.366516500711441\\
04, `psFlux': 7.698232025177276e-07, `psRa': None, `psDecl': None,
`ps\_Cov': Non\\
e, `psLnL': None, `psChi2': None, `psNdata': None, `trailFlux': None,
`trailRa':\\
etc.

\vspace{\dp0}
} \end{minipage} 


\\ \midrule

\end{longtable}




\subsection{ \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T218}{ LVV-T218 }
             - Simple Filtering of the LSST Alert Stream }\label{lvv-t218}





\begin{longtable}[]{llllll}
\toprule
Version & Status & Priority & Verification Type & Critical Event & Owner
\\\midrule
1 & Draft & Normal & Test & False & Eric Bellm
\\\bottomrule
\end{longtable}

\subsubsection{Requirements}

\begin{itemize}

\item \href{https://jira.lsstcorp.org/browse/LVV-173}{ LVV-173 } - DMS-REQ-0342-V-01: Alert Filtering Service

\item \href{https://jira.lsstcorp.org/browse/LVV-179}{ LVV-179 } - DMS-REQ-0348-V-01: Pre-defined alert filters

\item \href{https://jira.lsstcorp.org/browse/LVV-174}{ LVV-174 } - DMS-REQ-0343-V-01: Performance Requirements for LSST Alert Filtering Service

\end{itemize}


\subsubsection{Test Items}

This test will demonstrate the ``mini-broker'' filtering service that
returns a subset of alerts from the full stream identified by
user-provided filters.\\[2\baselineskip]Specifically, this will
demonstrate that:\\

\begin{itemize}
\tightlist
\item
  The filtering service can retrieve alerts from the full alert stream
  and filter them according to their contents; ~ ~
\item
  The filtered subset can be delivered to science users.
\end{itemize}





\subsubsection{Intercase Dependencies}

â€‹\href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T216}{LVV-T216}â€‹â€‹â€‹\\
â€‹\href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T217}{LVV-T217}â€‹â€‹â€‹



\subsubsection{Environment Needs}

\paragraph{Software}

The Kafka cluster and Zookeeper shall be instantiated according to the
procedure described in
\href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T216}{LVV-T216}.



\paragraph{Hardware}

This test case shall be executed on the Kubernetes Commons at the LDF.\\
As discussed in https://dmtn-028.lsst.io/ and https://dmtn-081.lsst.io/,
the test machine should have at least 16 cores, 64 GB of memory and
access to at least 1.5 TB of shared storage.



\subsubsection{Input Specification}

Input data: A sample of Avro-formatted alert packets derived from LSST
simulations corresponding to one night of simulated LSST observing.



\subsubsection{Output Specification}


\subsubsection{Test Procedure}

\begin{longtable}[]{p{1.3cm}p{2cm}p{13cm}}
%\toprule
Step & \multicolumn{2}{@{}l}{Description, Input Data and Expected Result} \\ \toprule
\endhead






\multirow{3}{*}{\parbox{1.3cm}{ 1-1 {\scriptsize from \hyperref[lvv-t216]{LVV-T216} } } } 
& {\small Description} &
\begin{minipage}[t]{13cm}{\scriptsize
Download Kafka Docker image from
https://github.com/lsst-dm/alert\_stream.

\vspace{\dp0}
} \end{minipage} \\ \cdashline{2-3}
& {\small Test Data} & 
\begin{minipage}[t]{13cm}{\scriptsize

No data.
\vspace{\dp0}

} \end{minipage} \\ \cdashline{2-3}
& {\small Expected Result} &

\begin{minipage}[t]{13cm}{\scriptsize
Runs without error

\vspace{\dp0}
} \end{minipage}

\\ \hdashline



\multirow{3}{*}{\parbox{1.3cm}{ 1-2 {\scriptsize from \hyperref[lvv-t216]{LVV-T216} } } } 
& {\small Description} &
\begin{minipage}[t]{13cm}{\scriptsize
Change to the alert\_stream directory and build the docker image.\\

\begin{verbatim}
docker build -t "lsst-kub001:5000/alert_stream"
\end{verbatim}

\vspace{\dp0}
} \end{minipage} \\ \cdashline{2-3}
& {\small Test Data} & 
\begin{minipage}[t]{13cm}{\scriptsize

No data.
\vspace{\dp0}

} \end{minipage} \\ \cdashline{2-3}
& {\small Expected Result} &

\begin{minipage}[t]{13cm}{\scriptsize
Runs without error

\vspace{\dp0}
} \end{minipage}

\\ \hdashline



\multirow{3}{*}{\parbox{1.3cm}{ 1-3 {\scriptsize from \hyperref[lvv-t216]{LVV-T216} } } } 
& {\small Description} &
\begin{minipage}[t]{13cm}{\scriptsize
Register it with Kubernetes\\[2\baselineskip]docker push
lsst-kub001:5000/alert\_stream

\vspace{\dp0}
} \end{minipage} \\ \cdashline{2-3}
& {\small Test Data} & 
\begin{minipage}[t]{13cm}{\scriptsize

No data.
\vspace{\dp0}

} \end{minipage} \\ \cdashline{2-3}
& {\small Expected Result} &

\begin{minipage}[t]{13cm}{\scriptsize
Runs without error

\vspace{\dp0}
} \end{minipage}

\\ \hdashline



\multirow{3}{*}{\parbox{1.3cm}{ 1-4 {\scriptsize from \hyperref[lvv-t216]{LVV-T216} } } } 
& {\small Description} &
\begin{minipage}[t]{13cm}{\scriptsize
From the alert\_stream/kubernetes directory, start Kafka and
Zookeeper:\\[2\baselineskip]

\begin{verbatim}
kubectl create -f zookeeper-service.yaml
kubectl create -f zookeeper-deployment.yaml
kubectl create -f kafka-deployment.yaml
kubectl create -f kafka-service.yaml
\end{verbatim}

(use kubectl get pods/services between each command to check status;
wait until each is ``Running'' before starting the next
command)\\[2\baselineskip]

\vspace{\dp0}
} \end{minipage} \\ \cdashline{2-3}
& {\small Test Data} & 
\begin{minipage}[t]{13cm}{\scriptsize

No data.
\vspace{\dp0}

} \end{minipage} \\ \cdashline{2-3}
& {\small Expected Result} &

\begin{minipage}[t]{13cm}{\scriptsize
Runs without error

\vspace{\dp0}
} \end{minipage}

\\ \hdashline



\multirow{3}{*}{\parbox{1.3cm}{ 1-5 {\scriptsize from \hyperref[lvv-t216]{LVV-T216} } } } 
& {\small Description} &
\begin{minipage}[t]{13cm}{\scriptsize
Confirm Kafka and Zookeeper are listed when
running\\[2\baselineskip]kubectl get
pods\\[2\baselineskip]and\\[2\baselineskip]kubectl get services

\vspace{\dp0}
} \end{minipage} \\ \cdashline{2-3}
& {\small Test Data} & 
\begin{minipage}[t]{13cm}{\scriptsize

No data.
\vspace{\dp0}

} \end{minipage} \\ \cdashline{2-3}
& {\small Expected Result} &

\begin{minipage}[t]{13cm}{\scriptsize
Output should be similar to:\\[2\baselineskip]kubectl get pods\\
NAME ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~READY ~ ~ STATUS ~ ~RESTARTS ~ AGE\\
kafka-768ddf5564-xwgvh ~ ~ ~1/1 ~ ~ ~ Running ~ 0 ~ ~ ~ ~ ~31s\\
zookeeper-f798cc548-mgkpn ~ 1/1 ~ ~ ~ Running ~ 0 ~ ~ ~ ~
~1m\\[2\baselineskip]kubectl get services\\
NAME ~ ~ ~ ~TYPE ~ ~ ~ ~CLUSTER-IP ~ ~ ~EXTERNAL-IP ~ PORT(S) ~ ~ AGE\\
kafka ~ ~ ~ ClusterIP ~ 10.105.19.124 ~ \textless{}none\textgreater{} ~
~ ~ ~9092/TCP ~ ~6s\\
zookeeper ~ ClusterIP ~ 10.97.110.124 ~ \textless{}none\textgreater{} ~
~ ~ ~32181/TCP ~ 2m

\vspace{\dp0}
} \end{minipage}

\\ \hdashline




\\ \midrule



\multirow{3}{*}{ 2 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Start 100 consumers that consume the filtered streams and logs a
deserialized version of every Nth packet:\\[2\baselineskip]

\begin{verbatim}
kubectl create -f consumer1-deployment.yaml
kubectl create -f consumer2-deployment.yaml
kubectl create -f consumer3-deployment.yaml
kubectl create -f consumer4-deployment.yaml
kubectl create -f consumer5-deployment.yaml
kubectl create -f consumer6-deployment.yaml
kubectl create -f consumer7-deployment.yaml
kubectl create -f consumer8-deployment.yaml
kubectl create -f consumer9-deployment.yaml
kubectl create -f consumer10-deployment.yaml
\end{verbatim}
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
Runs without error

\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 3 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Start 5 filter groups:\\

\begin{verbatim}
kubectl create -f filterer1-deployment.yaml
kubectl create -f filterer2-deployment.yaml
kubectl create -f filterer3-deployment.yaml
kubectl create -f filterer4-deployment.yaml
kubectl create -f filterer5-deployment.yaml
\end{verbatim}
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
Runs without error

\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 4 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Start a producer that reads alert packets from disk and loads them into
the Kafka queue:\\[2\baselineskip]

\begin{verbatim}
kubectl create -f sender-deployment.yaml
\end{verbatim}
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
Runs without error

\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 5 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Determine the name of the alert sender pod with\\[2\baselineskip]kubectl
get pods\\[2\baselineskip]Examine output log
files.\\[2\baselineskip]kubectl logs \textless{}pod
name\textgreater{}\\[2\baselineskip]Verify that alerts are being sent
within 40 seconds by subtracting the timing measurements.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
Similar to\\[2\baselineskip]kubectl logs sender-7d6f98586f-nhwfj\\
visit: 1570. ~ ~ time: 1530588618.0313473\\
visits finished: 1 ~ ~ ~time: 1530588653.5614944\\
visit: 1571. ~ ~ time: 1530588657.0087624\\
visits finished: 2 ~ ~ ~time: 1530588692.506188\\
visit: 1572. ~ ~ time: 1530588696.0051727\\
visits finished: 3 ~ ~ ~time: 1530588731.5900314\\[2\baselineskip]

\vspace{\dp0}
} \end{minipage} 


\\ \midrule



\multirow{3}{*}{ 6 } & Description &
\begin{minipage}[t]{13cm}{\footnotesize
Determine the name of the consumer pods with\\[2\baselineskip]kubectl
get pods\\[2\baselineskip]Examine output log
files.\\[2\baselineskip]kubectl logs \textless{}pod
name\textgreater{}\\[2\baselineskip]The packet log should show
deserialized alert packets with contents matching the input packets.
 
\vspace{\dp0}
} \end{minipage} \\ \cline{2-3}
& Test Data & 
\begin{minipage}[t]{13cm}{\footnotesize

No data. 
\vspace{\dp0}

} \end{minipage} \\ \cline{2-3}
& Expected Result &

\begin{minipage}[t]{13cm}{\footnotesize
Similar to\\[2\baselineskip]\{'alertId': 12132024420, `l1dbId':
71776805594116, `diaSource': \{'diaSourceId':\\
73499448928374785, `ccdVisitId': 2020011570, `diaObjectId':
71776805594116, 'ssO\\
bjectId': None, `parentDiaSourceId': None, `midPointTai': 59595.37041,
'filterNa\\
me': `y', `ra': 172.24912810036074, `decl': -80.64214929176521,
`ra\_decl\_Cov': \{\\
`raSigma': 0.0003428002819418907, `declSigma': 0.00027273103478364646,
'ra\_decl\_\\
Cov': 0.000628734880592674\}, `x': 2979.08837890625, `y':
3843.328857421875, 'x\_y\\
\_Cov': \{'xSigma': 0.6135467886924744, `ySigma': 0.77132648229599,
`x\_y\_Cov': 0.0\\
007463791407644749\}, `apFlux': None, `apFluxErr': None, `snr':
0.366516500711441\\
04, `psFlux': 7.698232025177276e-07, `psRa': None, `psDecl': None,
`ps\_Cov': Non\\
e, `psLnL': None, `psChi2': None, `psNdata': None, `trailFlux': None,
`trailRa':\\
etc.

\vspace{\dp0}
} \end{minipage} 


\\ \midrule

\end{longtable}




